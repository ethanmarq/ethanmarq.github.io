---
title: "Efficient Vision Transformers for Autonomous Off-Road Perception Systems"
collection: publications
category: conferences
permalink: /publication/efficientVitOffRoad
excerpt: 'This paper is about developing systems of Unmaned Ground Vehicles (UGVs) that can navigate off-road environments using vision transformers.'
date: 2024-9-06
venue: 'Journal of Computer and Communications'
slidesurl: #'http://academicpages.github.io/files/slides1.pdf'
paperurl: #'http://academicpages.github.io/files/paper1.pdf'
citation: 'III, M. , Pickeral, A. , Marquez, E. , Smith, M. and Calhoun, J. (2024) Efficient Vision Transformers for Autonomous Off-Road Perception Systems. Journal of Computer and Communications, 12, 188-207. doi: 10.4236/jcc.2024.129011.'
---


The development of autonomous vehicles has become one of the greatest research endeavors in recent 
years. These vehicles rely on many complex systems working in tandem to make decisions. For practical 
use and safety reasons, these systems must not only be accurate, but also quickly detect changes in 
the surrounding environment. In autonomous vehicle research, the environment perception system is one
of the key components of development. Environment perception systems allow the vehicle to understand
its surroundings. This is done by using cameras, light detection and ranging (LiDAR), with other 
sensor systems and modalities. Deep learning computer vision algorithms have been shown to be the 
strongest tool for translating camera data into accurate and safe traversability decisions regarding
the environment surrounding a vehicle. In order for a vehicle to safely traverse an area in real
time, these computer vision algorithms must be accurate and have low latency. While much research
has studied autonomous driving for traversing well-structured urban environments, limited research
exists evaluating perception system improvements in off-road settings. This research aims to
investigate the adaptability of several existing deep-learning architectures for semantic
segmentation in off-road environments. Previous studies of two Convolutional Neural Network (CNN) 
architectures are included for comparison with new evaluation of Vision Transformer (ViT) 
architectures for semantic segmentation. Our results demonstrate viability of ViT architectures for
off-road perception systems, having a strong segmentation accuracy, lower inference speed and
memory footprint compared to previous results with CNN architectures.